{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf75b53113ac4fe8a9529a2681406b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_090b6e8d9fed47f8b1d1544a97524daa",
              "IPY_MODEL_e2113228d4b941e98beed94ab37c07a4",
              "IPY_MODEL_7eb9ee3becfb4f6884e37c0adff2ca79"
            ],
            "layout": "IPY_MODEL_d407b53a14cc4c90aa6982a32e7655a5"
          }
        },
        "090b6e8d9fed47f8b1d1544a97524daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26302e687cdd4c6cb413933aa8982525",
            "placeholder": "​",
            "style": "IPY_MODEL_358d7fb3abb94082b2a2437838498b1c",
            "value": "config.json: 100%"
          }
        },
        "e2113228d4b941e98beed94ab37c07a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bca0beb35884ec6a758bbaabdd66f84",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_638db4406b9347d99bd440b43c64f018",
            "value": 481
          }
        },
        "7eb9ee3becfb4f6884e37c0adff2ca79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e25529ff4e4d4effacb524aee9834980",
            "placeholder": "​",
            "style": "IPY_MODEL_0cc753ff5bfa4322aa39df63e0f55a04",
            "value": " 481/481 [00:00&lt;00:00, 21.8kB/s]"
          }
        },
        "d407b53a14cc4c90aa6982a32e7655a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26302e687cdd4c6cb413933aa8982525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "358d7fb3abb94082b2a2437838498b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bca0beb35884ec6a758bbaabdd66f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638db4406b9347d99bd440b43c64f018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e25529ff4e4d4effacb524aee9834980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc753ff5bfa4322aa39df63e0f55a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f93d5404c1d42419c1cf870ae68c21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_569f2f2190cb47f38ce98a4c340b72a6",
              "IPY_MODEL_a6eabe3d0dea4c5aa2d2058dbc999bd2",
              "IPY_MODEL_9fdae4b6b6104c49b2b77c7dcf85b5da"
            ],
            "layout": "IPY_MODEL_808d3f20282c45fa9e3faa290ed13c3a"
          }
        },
        "569f2f2190cb47f38ce98a4c340b72a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6975070932f45099adb0413599a33f7",
            "placeholder": "​",
            "style": "IPY_MODEL_62c133a6d2a54b47b6dd5d8117d1dee4",
            "value": "vocab.json: 100%"
          }
        },
        "a6eabe3d0dea4c5aa2d2058dbc999bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f5cc7beeeb14a8e9f8b3c14753fa652",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_162b18c4d0054b978c42501556e26620",
            "value": 898823
          }
        },
        "9fdae4b6b6104c49b2b77c7dcf85b5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9347c81e877142c5aa2c9c7693ed0b00",
            "placeholder": "​",
            "style": "IPY_MODEL_1150562ad1704dbe95dd95c083062f43",
            "value": " 899k/899k [00:00&lt;00:00, 4.56MB/s]"
          }
        },
        "808d3f20282c45fa9e3faa290ed13c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6975070932f45099adb0413599a33f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c133a6d2a54b47b6dd5d8117d1dee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f5cc7beeeb14a8e9f8b3c14753fa652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "162b18c4d0054b978c42501556e26620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9347c81e877142c5aa2c9c7693ed0b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1150562ad1704dbe95dd95c083062f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6810f2959ab4e1bb3c17a6bd50aefb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05063e0306264eb7b8f9f07a4d265100",
              "IPY_MODEL_c6297e6893744aee8b33ec47bfc4bca5",
              "IPY_MODEL_d3fbc7ef12624ba3bda34921f712868f"
            ],
            "layout": "IPY_MODEL_de27470572e04cab9cf5e0c8c1487040"
          }
        },
        "05063e0306264eb7b8f9f07a4d265100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9818d5ce453437eb86ec95e31f5316a",
            "placeholder": "​",
            "style": "IPY_MODEL_f52c215cbe9e49edab611614f305353c",
            "value": "merges.txt: 100%"
          }
        },
        "c6297e6893744aee8b33ec47bfc4bca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1f743029a040ec96021d466fba7809",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdfec0df30644d64858fadae06934496",
            "value": 456318
          }
        },
        "d3fbc7ef12624ba3bda34921f712868f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00c91aa4c54f4d44becd5e4f4ff4fb55",
            "placeholder": "​",
            "style": "IPY_MODEL_97b999e51429407ab408038f4a6df689",
            "value": " 456k/456k [00:00&lt;00:00, 3.64MB/s]"
          }
        },
        "de27470572e04cab9cf5e0c8c1487040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9818d5ce453437eb86ec95e31f5316a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52c215cbe9e49edab611614f305353c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1f743029a040ec96021d466fba7809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdfec0df30644d64858fadae06934496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00c91aa4c54f4d44becd5e4f4ff4fb55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b999e51429407ab408038f4a6df689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3063f9bbb91b467cbcbf3ad0cb39b544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_962ddb6da6174092806898d356293d0d",
              "IPY_MODEL_9dd08cd8273248178ebca1c7e45b8152",
              "IPY_MODEL_1d7c4d554d7044cdb6a753b87713863a"
            ],
            "layout": "IPY_MODEL_478ea0fa1531415dba8cab68d15eeb83"
          }
        },
        "962ddb6da6174092806898d356293d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dae967ccd7924080afa115f3b08526b1",
            "placeholder": "​",
            "style": "IPY_MODEL_af9f86219eca47168a4e7dbbbd4cb140",
            "value": "tokenizer.json: 100%"
          }
        },
        "9dd08cd8273248178ebca1c7e45b8152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab850646936f4812bda3c9407a650129",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32cef7d190174aabaf37c5960b18990f",
            "value": 1355863
          }
        },
        "1d7c4d554d7044cdb6a753b87713863a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cda7fcd21ce4397a58bce4fb89033ea",
            "placeholder": "​",
            "style": "IPY_MODEL_a507b49df1f648139110bda6973e8661",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 29.1MB/s]"
          }
        },
        "478ea0fa1531415dba8cab68d15eeb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae967ccd7924080afa115f3b08526b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9f86219eca47168a4e7dbbbd4cb140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab850646936f4812bda3c9407a650129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32cef7d190174aabaf37c5960b18990f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cda7fcd21ce4397a58bce4fb89033ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a507b49df1f648139110bda6973e8661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72c6e1d1c17c4e7e9a2112308ab0a195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50b493f9a4194921b1d70817b0bbbcd1",
              "IPY_MODEL_aa39ee3ba3364e29b96a0cb9dd7013c5",
              "IPY_MODEL_4dc0664a26d44d07844b34fbf54dcae0"
            ],
            "layout": "IPY_MODEL_1eb88bb073a34651a14280315656eea2"
          }
        },
        "50b493f9a4194921b1d70817b0bbbcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b982ce680c7f474f91e8b14ddc116be6",
            "placeholder": "​",
            "style": "IPY_MODEL_6914f55e5ee045f68a2962abbca6d61b",
            "value": "model.safetensors: 100%"
          }
        },
        "aa39ee3ba3364e29b96a0cb9dd7013c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04b92ea3f23447f3b6bb0cd07d76bccc",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b84d3032c64b629022dd19650f3dd9",
            "value": 498818054
          }
        },
        "4dc0664a26d44d07844b34fbf54dcae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ae109164b70414fba33368d78ead82f",
            "placeholder": "​",
            "style": "IPY_MODEL_2459672cb3f644dbb46b71922cb086c9",
            "value": " 499M/499M [00:04&lt;00:00, 134MB/s]"
          }
        },
        "1eb88bb073a34651a14280315656eea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b982ce680c7f474f91e8b14ddc116be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6914f55e5ee045f68a2962abbca6d61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04b92ea3f23447f3b6bb0cd07d76bccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b84d3032c64b629022dd19650f3dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ae109164b70414fba33368d78ead82f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2459672cb3f644dbb46b71922cb086c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "conducted by:\n",
        "\n",
        "- Mirco Lescart\n",
        "\n",
        "- Freddy Fernandes\n",
        "\n",
        "- Arina Sadeghi Khiabanian\n",
        "\n",
        "- Parsa Mastouri Kashani"
      ],
      "metadata": {
        "id": "MIqDY1i7_o4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the transformers library and additional libraries:"
      ],
      "metadata": {
        "id": "smjLjk3fLWnk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG6U6nUPonas",
        "outputId": "b53121da-a465-41e2-cf8b-6c08a777016b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlcm\n",
            "  Downloading mlcm-0.0.1-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mlcm) (1.23.5)\n",
            "Installing collected packages: mlcm\n",
            "Successfully installed mlcm-0.0.1\n",
            "Collecting datasets==2.13.2\n",
            "  Downloading datasets-2.13.2-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (10.0.1)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.13.2)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.4.1)\n",
            "Collecting multiprocess (from datasets==2.13.2)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.2) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.2) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.2) (2023.11.17)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.13.2) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.13.2) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.13.2 dill-0.3.6 multiprocess-0.70.14\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.1\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "!pip install mlcm\n",
        "\n",
        "!pip install datasets==2.13.2\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate\n",
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing stock ml libraries"
      ],
      "metadata": {
        "id": "_h4H6mXXL0ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ],
      "metadata": {
        "id": "kPUlGSo8ouUn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the device for GPU usage if available"
      ],
      "metadata": {
        "id": "Px54xMy8MOXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIZnOzVYMNci",
        "outputId": "53a9b6b4-fc5a-4d23-bacd-a0e97889e631"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "ZjD4R3FcNmT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the data and making them into pandas dataframes:"
      ],
      "metadata": {
        "id": "g0j7GDwkMWVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args_train = pd.read_csv(\"arguments-training.tsv\", delimiter='\\t')\n",
        "labels_train = pd.read_csv(\"labels-training.tsv\", delimiter='\\t')\n",
        "\n",
        "args_validation = pd.read_csv(\"arguments-validation.tsv\", delimiter='\\t')\n",
        "labels_validation = pd.read_csv(\"labels-validation.tsv\", delimiter='\\t')\n",
        "\n",
        "args_test = pd.read_csv(\"arguments-test.tsv\", delimiter='\\t')\n",
        "labels_test = pd.read_csv(\"labels-test.tsv\", delimiter='\\t')"
      ],
      "metadata": {
        "id": "hG2ViZ-CpFqC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the necessary logic to get level 3 category features:"
      ],
      "metadata": {
        "id": "nGhDfqKHMft7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_level3(df):\n",
        "\n",
        "  columns_to_include = ['Self-direction: thought',\n",
        "                        'Self-direction: action',\n",
        "                        'Stimulation',\n",
        "                        'Hedonism']\n",
        "  df['Openness to change'] = df[columns_to_include].apply(lambda row: any(row == 1), axis=1).astype(int)\n",
        "\n",
        "  columns_to_include = ['Hedonism',\n",
        "                        'Achievement',\n",
        "                        'Stimulation',\n",
        "                        'Power: dominance',\n",
        "                        'Power: resources',\n",
        "                        'Face']\n",
        "  df['Self-enhancement'] = df[columns_to_include].apply(lambda row: any(row == 1), axis=1).astype(int)\n",
        "\n",
        "  columns_to_include = ['Face',\n",
        "                      'Security: personal',\n",
        "                      'Security: societal',\n",
        "                      'Security: societal',\n",
        "                      'Tradition',\n",
        "                      'Conformity: rules',\n",
        "                      'Conformity: interpersonal',\n",
        "                      'Humility']\n",
        "  df['Conservation'] = df[columns_to_include].apply(lambda row: any(row == 1), axis=1).astype(int)\n",
        "\n",
        "  columns_to_include = ['Humility',\n",
        "                        'Benevolence: caring',\n",
        "                        'Benevolence: dependability',\n",
        "                        'Universalism: concern',\n",
        "                        'Universalism: nature',\n",
        "                        'Universalism: tolerance',\n",
        "                        'Universalism: objectivity']\n",
        "  df['Self-transcendence'] = df[columns_to_include].apply(lambda row: any(row == 1), axis=1).astype(int)\n",
        "\n",
        "  return df.iloc[:, -4:]"
      ],
      "metadata": {
        "id": "eCwqmw5vpXcb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train = concat_level3(labels_train)\n",
        "labels_validation = concat_level3(labels_validation)\n",
        "labels_test = concat_level3(labels_test)"
      ],
      "metadata": {
        "id": "YqCr4-ixpYTY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenating the labels and the arguments together"
      ],
      "metadata": {
        "id": "7LkYMwLpM1Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate along columns (axis=1)\n",
        "train_set = pd.concat([args_train, labels_train], axis=1)\n",
        "validation_set = pd.concat([args_validation, labels_validation], axis=1)\n",
        "test_set = pd.concat([args_test, labels_test], axis=1)"
      ],
      "metadata": {
        "id": "1thTQWrupiaM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We drop Argument ID because it's irrelevant in our problem"
      ],
      "metadata": {
        "id": "TuLkdTzTNuNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_set.drop('Argument ID', axis=1)\n",
        "validation_set = validation_set.drop('Argument ID', axis=1)\n",
        "test_set = test_set.drop('Argument ID', axis=1)"
      ],
      "metadata": {
        "id": "EQ3f04Agplya"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We turn 'in favor of' and 'against' into 0 and 1 because it's easier to feed the model directly and it also takes less tokens to tokenize."
      ],
      "metadata": {
        "id": "RjRlHwg7N2Lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['Stance'] = train_set['Stance'].replace({'in favor of': 1, 'against': 0})\n",
        "validation_set['Stance'] = validation_set['Stance'].replace({'in favor of': 1, 'against': 0})\n",
        "test_set['Stance'] = test_set['Stance'].replace({'in favor of': 1, 'against': 0})"
      ],
      "metadata": {
        "id": "4ne2wsV9poLA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "vh0awjFRw97l",
        "outputId": "7199d6bb-cc92-4df2-c7fb-a43343ae2774"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Conclusion  Stance  \\\n",
              "0                  We should ban human cloning       1   \n",
              "1                      We should ban fast food       1   \n",
              "2  We should end the use of economic sanctions       0   \n",
              "3         We should abolish capital punishment       0   \n",
              "4                We should ban factory farming       0   \n",
              "\n",
              "                                             Premise  Openness to change  \\\n",
              "0  we should ban human cloning as it will only ca...                   0   \n",
              "1  fast food should be banned because it is reall...                   0   \n",
              "2  sometimes economic sanctions are the only thin...                   0   \n",
              "3  capital punishment is sometimes the only optio...                   0   \n",
              "4  factory farming allows for the production of c...                   0   \n",
              "\n",
              "   Self-enhancement  Conservation  Self-transcendence  \n",
              "0                 0             1                   0  \n",
              "1                 0             1                   0  \n",
              "2                 1             1                   0  \n",
              "3                 0             1                   1  \n",
              "4                 0             1                   1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5daa074d-baf4-4667-a5e2-b645f94412af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Conclusion</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Premise</th>\n",
              "      <th>Openness to change</th>\n",
              "      <th>Self-enhancement</th>\n",
              "      <th>Conservation</th>\n",
              "      <th>Self-transcendence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We should ban human cloning</td>\n",
              "      <td>1</td>\n",
              "      <td>we should ban human cloning as it will only ca...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We should ban fast food</td>\n",
              "      <td>1</td>\n",
              "      <td>fast food should be banned because it is reall...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We should end the use of economic sanctions</td>\n",
              "      <td>0</td>\n",
              "      <td>sometimes economic sanctions are the only thin...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We should abolish capital punishment</td>\n",
              "      <td>0</td>\n",
              "      <td>capital punishment is sometimes the only optio...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We should ban factory farming</td>\n",
              "      <td>0</td>\n",
              "      <td>factory farming allows for the production of c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5daa074d-baf4-4667-a5e2-b645f94412af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5daa074d-baf4-4667-a5e2-b645f94412af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5daa074d-baf4-4667-a5e2-b645f94412af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-58eb0ddd-da87-4e9b-b677-e4677da21d0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58eb0ddd-da87-4e9b-b677-e4677da21d0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-58eb0ddd-da87-4e9b-b677-e4677da21d0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "ipyHmWi2OMyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model"
      ],
      "metadata": {
        "id": "ZsVjVDEfBWT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "0hpQrymnpwNe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "num_labels = 4\n",
        "classifiers = []\n",
        "f1_scores = []\n",
        "accuracies = []\n",
        "\n",
        "for label in range(num_labels):\n",
        "\n",
        "    # Create a random uniform classifier for the current label\n",
        "    random_classifier = DummyClassifier(strategy='uniform')\n",
        "\n",
        "    random_classifier.fit(train_set.iloc[:, :3], train_set.iloc[:, label+3])\n",
        "\n",
        "    # Predict\n",
        "    predictions = random_classifier.predict(test_set.iloc[:, :3])\n",
        "\n",
        "    classifiers.append(random_classifier)\n",
        "\n",
        "    # # Calculate accuracy for the current label\n",
        "    # accuracy = accuracy_score(test_set.iloc[:, label+3], predictions)\n",
        "    # accuracies.append(accuracy)\n",
        "\n",
        "    # # Calculate F1 score for the current label\n",
        "    # f1 = f1_score(test_set.iloc[:, label+3], predictions)\n",
        "    # f1_scores.append(f1)\n",
        "\n",
        "    print(f'{train_set.columns[3+label]}: ')\n",
        "\n",
        "    print(classification_report(test_set.iloc[:, label+3], predictions))\n",
        "\n",
        "    # print(f\"Label {label}: Accuracy = {accuracy:.4f}, F1 score = {f1:.4f},   {train_set.columns[3+label]}\")\n",
        "\n",
        "#print(f\"Overall F1 score: {sum(f1_scores)/len(f1_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y5DsmPyptMH",
        "outputId": "a02f5a3f-d6a7-47ed-bbf2-bb3c9f1b7e9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Openness to change: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.49      0.58      1102\n",
            "           1       0.30      0.52      0.38       474\n",
            "\n",
            "    accuracy                           0.50      1576\n",
            "   macro avg       0.50      0.50      0.48      1576\n",
            "weighted avg       0.58      0.50      0.52      1576\n",
            "\n",
            "Self-enhancement: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.48      0.51       892\n",
            "           1       0.41      0.48      0.44       684\n",
            "\n",
            "    accuracy                           0.48      1576\n",
            "   macro avg       0.48      0.48      0.47      1576\n",
            "weighted avg       0.49      0.48      0.48      1576\n",
            "\n",
            "Conservation: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.50      0.37       457\n",
            "           1       0.72      0.51      0.60      1119\n",
            "\n",
            "    accuracy                           0.51      1576\n",
            "   macro avg       0.51      0.51      0.48      1576\n",
            "weighted avg       0.59      0.51      0.53      1576\n",
            "\n",
            "Self-transcendence: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.49      0.27       308\n",
            "           1       0.80      0.50      0.61      1268\n",
            "\n",
            "    accuracy                           0.50      1576\n",
            "   macro avg       0.50      0.49      0.44      1576\n",
            "weighted avg       0.68      0.50      0.55      1576\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "num_labels = 4\n",
        "classifiers = []\n",
        "f1_scores = []\n",
        "accuracies = []\n",
        "\n",
        "for label in range(num_labels):\n",
        "\n",
        "    # Create a random uniform classifier for the current label\n",
        "    random_classifier = DummyClassifier(strategy='most_frequent')\n",
        "\n",
        "    random_classifier.fit(train_set.iloc[:, :3], train_set.iloc[:, label+3])\n",
        "\n",
        "    # Predict\n",
        "    predictions = random_classifier.predict(test_set.iloc[:, :3])\n",
        "\n",
        "    classifiers.append(random_classifier)\n",
        "\n",
        "    # # Calculate accuracy for the current label\n",
        "    # accuracy = accuracy_score(test_set.iloc[:, label+3], predictions)\n",
        "    # accuracies.append(accuracy)\n",
        "\n",
        "    # # Calculate F1 score for the current label\n",
        "    # f1 = f1_score(test_set.iloc[:, label+3], predictions, average='micro')\n",
        "    # f1_scores.append(f1)\n",
        "\n",
        "    print(f'{train_set.columns[3+label]}: ')\n",
        "\n",
        "    print(classification_report(test_set.iloc[:, label+3], predictions, zero_division=1))\n",
        "\n",
        "    #print(f\"Label {label}: Accuracy = {accuracy:.4f}, F1 score = {f1:.4f},   {train_set.columns[3+label]}\")\n",
        "\n",
        "#print(f\"Overall F1 score: {sum(f1_scores)/len(f1_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgmjqllUpyh_",
        "outputId": "221b0146-e28d-40e4-cf73-43e8d6513f91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Openness to change: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      1.00      0.82      1102\n",
            "           1       1.00      0.00      0.00       474\n",
            "\n",
            "    accuracy                           0.70      1576\n",
            "   macro avg       0.85      0.50      0.41      1576\n",
            "weighted avg       0.79      0.70      0.58      1576\n",
            "\n",
            "Self-enhancement: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      1.00      0.72       892\n",
            "           1       1.00      0.00      0.00       684\n",
            "\n",
            "    accuracy                           0.57      1576\n",
            "   macro avg       0.78      0.50      0.36      1576\n",
            "weighted avg       0.75      0.57      0.41      1576\n",
            "\n",
            "Conservation: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00       457\n",
            "           1       0.71      1.00      0.83      1119\n",
            "\n",
            "    accuracy                           0.71      1576\n",
            "   macro avg       0.86      0.50      0.42      1576\n",
            "weighted avg       0.79      0.71      0.59      1576\n",
            "\n",
            "Self-transcendence: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00       308\n",
            "           1       0.80      1.00      0.89      1268\n",
            "\n",
            "    accuracy                           0.80      1576\n",
            "   macro avg       0.90      0.50      0.45      1576\n",
            "weighted avg       0.84      0.80      0.72      1576\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "--taAfbWp_kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sections of config\n",
        "# bert-base-uncased\n",
        "# prajjwal1/bert-tiny\n",
        "# distilbert-base-uncased\n",
        "# roberta-base\n",
        "card_name = 'roberta-base'\n",
        "labels = ['Openness to change', 'Conservation', 'Self-enhancement', 'Self-transcendence']\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 250\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 2e-05\n",
        "tokenizer = AutoTokenizer.from_pretrained(card_name)"
      ],
      "metadata": {
        "id": "ObZbCi_Np4Zd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "bf75b53113ac4fe8a9529a2681406b0f",
            "090b6e8d9fed47f8b1d1544a97524daa",
            "e2113228d4b941e98beed94ab37c07a4",
            "7eb9ee3becfb4f6884e37c0adff2ca79",
            "d407b53a14cc4c90aa6982a32e7655a5",
            "26302e687cdd4c6cb413933aa8982525",
            "358d7fb3abb94082b2a2437838498b1c",
            "2bca0beb35884ec6a758bbaabdd66f84",
            "638db4406b9347d99bd440b43c64f018",
            "e25529ff4e4d4effacb524aee9834980",
            "0cc753ff5bfa4322aa39df63e0f55a04",
            "3f93d5404c1d42419c1cf870ae68c21b",
            "569f2f2190cb47f38ce98a4c340b72a6",
            "a6eabe3d0dea4c5aa2d2058dbc999bd2",
            "9fdae4b6b6104c49b2b77c7dcf85b5da",
            "808d3f20282c45fa9e3faa290ed13c3a",
            "b6975070932f45099adb0413599a33f7",
            "62c133a6d2a54b47b6dd5d8117d1dee4",
            "4f5cc7beeeb14a8e9f8b3c14753fa652",
            "162b18c4d0054b978c42501556e26620",
            "9347c81e877142c5aa2c9c7693ed0b00",
            "1150562ad1704dbe95dd95c083062f43",
            "a6810f2959ab4e1bb3c17a6bd50aefb2",
            "05063e0306264eb7b8f9f07a4d265100",
            "c6297e6893744aee8b33ec47bfc4bca5",
            "d3fbc7ef12624ba3bda34921f712868f",
            "de27470572e04cab9cf5e0c8c1487040",
            "a9818d5ce453437eb86ec95e31f5316a",
            "f52c215cbe9e49edab611614f305353c",
            "7f1f743029a040ec96021d466fba7809",
            "bdfec0df30644d64858fadae06934496",
            "00c91aa4c54f4d44becd5e4f4ff4fb55",
            "97b999e51429407ab408038f4a6df689",
            "3063f9bbb91b467cbcbf3ad0cb39b544",
            "962ddb6da6174092806898d356293d0d",
            "9dd08cd8273248178ebca1c7e45b8152",
            "1d7c4d554d7044cdb6a753b87713863a",
            "478ea0fa1531415dba8cab68d15eeb83",
            "dae967ccd7924080afa115f3b08526b1",
            "af9f86219eca47168a4e7dbbbd4cb140",
            "ab850646936f4812bda3c9407a650129",
            "32cef7d190174aabaf37c5960b18990f",
            "4cda7fcd21ce4397a58bce4fb89033ea",
            "a507b49df1f648139110bda6973e8661"
          ]
        },
        "outputId": "a2b850f3-b2e6-4d04-daea-bc73af5395f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf75b53113ac4fe8a9529a2681406b0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f93d5404c1d42419c1cf870ae68c21b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6810f2959ab4e1bb3c17a6bd50aefb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3063f9bbb91b467cbcbf3ad0cb39b544"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.data = dataframe\n",
        "        self.data['list'] = dataframe[dataframe.columns[3:]].values.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.Conclusion = dataframe.Conclusion\n",
        "        self.Premise = dataframe.Premise\n",
        "        self.Stance = dataframe.Stance\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Stance)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        Stance = self.Stance[index]\n",
        "\n",
        "        Conclusion = str(self.Conclusion[index])\n",
        "        Conclusion = \" \".join(Conclusion.split())\n",
        "\n",
        "        Premise = str(self.Premise[index])\n",
        "        Premise = \" \".join(Premise.split())\n",
        "\n",
        "        CP_text = f\"|Conclusion| {Conclusion} |Premise| {Premise}\"\n",
        "        CPS_text = f\"|Stance| {Stance} |Conclusion| {Conclusion} |Premise| {Premise}\"\n",
        "\n",
        "        C_inputs = self.tokenizer.encode_plus(\n",
        "            Conclusion,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        C_ids = C_inputs['input_ids']\n",
        "        C_mask = C_inputs['attention_mask']\n",
        "        C_token_type_ids = C_inputs[\"token_type_ids\"]\n",
        "\n",
        "        Premise_inputs = self.tokenizer.encode_plus(\n",
        "            Premise,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        Premise_ids = Premise_inputs['input_ids']\n",
        "        Premise_mask = Premise_inputs['attention_mask']\n",
        "        Premise_token_type_ids = Premise_inputs[\"token_type_ids\"]\n",
        "\n",
        "        CP_inputs = self.tokenizer.encode_plus(\n",
        "            Premise,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        CP_ids = CP_inputs['input_ids']\n",
        "        CP_mask = CP_inputs['attention_mask']\n",
        "        CP_token_type_ids = CP_inputs[\"token_type_ids\"]\n",
        "\n",
        "        CPS_inputs = self.tokenizer.encode_plus(\n",
        "            CPS_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        CPS_ids = CPS_inputs['input_ids']\n",
        "        CPS_mask = CPS_inputs['attention_mask']\n",
        "        CPS_token_type_ids = CPS_inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            'C_ids': torch.tensor(C_ids, dtype=torch.long),\n",
        "            'C_mask': torch.tensor(C_mask, dtype=torch.long),\n",
        "            'C_token_type_ids': torch.tensor(C_token_type_ids, dtype=torch.long),\n",
        "\n",
        "            'Premise_ids': torch.tensor(Premise_ids, dtype=torch.long),\n",
        "            'Premise_mask': torch.tensor(Premise_mask, dtype=torch.long),\n",
        "            'Premise_token_type_ids': torch.tensor(Premise_token_type_ids, dtype=torch.long),\n",
        "\n",
        "            'CP_ids': torch.tensor(CP_ids, dtype=torch.long),\n",
        "            'CP_mask': torch.tensor(CP_mask, dtype=torch.long),\n",
        "            'CP_token_type_ids': torch.tensor(CP_token_type_ids, dtype=torch.long),\n",
        "\n",
        "            'CPS_ids': torch.tensor(CPS_ids, dtype=torch.long),\n",
        "            'CPS_mask': torch.tensor(CPS_mask, dtype=torch.long),\n",
        "            'CPS_token_type_ids': torch.tensor(CPS_token_type_ids, dtype=torch.long),\n",
        "\n",
        "            'Stance': torch.tensor(self.Stance[index], dtype=torch.float),\n",
        "\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
        "        }"
      ],
      "metadata": {
        "id": "M8WNFcGqqC-N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_set, tokenizer, MAX_LEN)\n",
        "validation_dataset = CustomDataset(validation_set, tokenizer, MAX_LEN)\n",
        "test_dataset = CustomDataset(test_set, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "FDVNjbMJvgqJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of the training dataset: {len(train_dataset)}\")\n",
        "print(f\"Shape of the validation dataset: {len(validation_dataset)}\")\n",
        "print(f\"Shape of the test dataset: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MGTvGEVmMty",
        "outputId": "7fe0a6a5-2b91-41a9-bd53-8b67c6479201"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the training dataset: 5393\n",
            "Shape of the validation dataset: 1896\n",
            "Shape of the test dataset: 1576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "validation_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(train_dataset, **train_params)\n",
        "validation_loader = DataLoader(validation_dataset, **validation_params)\n",
        "testing_loader = DataLoader(test_dataset, **test_params)"
      ],
      "metadata": {
        "id": "im7XhCfywOoM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self, card_name):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.transformer = AutoModel.from_pretrained(card_name, return_dict=False)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.dense1 = torch.nn.Linear(768, 384)\n",
        "        self.dense2 = torch.nn.Linear(384, 192)\n",
        "        self.dense3 = torch.nn.Linear(192, 4)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output = self.transformer(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
        "        output = self.dropout(output)\n",
        "        output = self.dense1(output)\n",
        "        output = F.relu(output)\n",
        "        output = self.dense2(output)\n",
        "        output = F.relu(output)\n",
        "        output = self.dense3(output)\n",
        "        return output\n",
        "\n",
        "C_model = BERTClass(card_name)\n",
        "C_model.to(device)\n",
        "\n",
        "CP_model = BERTClass(card_name)\n",
        "CP_model.to(device)\n",
        "\n",
        "CPS_model = BERTClass(card_name)\n",
        "CPS_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989,
          "referenced_widgets": [
            "72c6e1d1c17c4e7e9a2112308ab0a195",
            "50b493f9a4194921b1d70817b0bbbcd1",
            "aa39ee3ba3364e29b96a0cb9dd7013c5",
            "4dc0664a26d44d07844b34fbf54dcae0",
            "1eb88bb073a34651a14280315656eea2",
            "b982ce680c7f474f91e8b14ddc116be6",
            "6914f55e5ee045f68a2962abbca6d61b",
            "04b92ea3f23447f3b6bb0cd07d76bccc",
            "60b84d3032c64b629022dd19650f3dd9",
            "9ae109164b70414fba33368d78ead82f",
            "2459672cb3f644dbb46b71922cb086c9"
          ]
        },
        "id": "mwUOofK3x2ZN",
        "outputId": "7245daec-ed18-4098-bbd2-40db7e255517"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72c6e1d1c17c4e7e9a2112308ab0a195"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (transformer): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (dense1): Linear(in_features=768, out_features=384, bias=True)\n",
              "  (dense2): Linear(in_features=384, out_features=192, bias=True)\n",
              "  (dense3): Linear(in_features=192, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a model we came up with just for experimentation which gives the premise to one transformer and the conclusion to another one and then gets 768 features out of each of the transformers, then concatenates the features including the stance (just one feature) and feeds it to a dense layer (1537 by 100) which gets followed by two other dense layers."
      ],
      "metadata": {
        "id": "OusMNCjovl0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UltimaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UltimaClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l4 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(1537, 100)\n",
        "        self.l5 = torch.nn.Linear(100, 25)\n",
        "        self.l6 = torch.nn.Linear(25, 4)\n",
        "\n",
        "    def forward(self,\n",
        "                Stance,\n",
        "                Conclusion_ids,\n",
        "                Conclusion_mask,\n",
        "                Conclusion_token_type_ids,\n",
        "                Premise_ids,\n",
        "                Premise_mask,\n",
        "                Premise_token_type_ids):\n",
        "\n",
        "        _, output_Conclusion= self.l1(Conclusion_ids,\n",
        "                             Conclusion_mask,\n",
        "                             Conclusion_token_type_ids,\n",
        "                             return_dict=False)\n",
        "\n",
        "\n",
        "        _, output_Premise= self.l4(Premise_ids,\n",
        "                             Premise_mask,\n",
        "                             Premise_token_type_ids,\n",
        "                             return_dict=False)\n",
        "\n",
        "\n",
        "        output_Conclusion_wdrop = self.l2(output_Conclusion)\n",
        "        output_Premise_wdrop = self.l2(output_Premise)\n",
        "\n",
        "        # Assuming you want to concatenate along dimension 1\n",
        "        Stance = Stance.unsqueeze(1)\n",
        "\n",
        "        concatenated_input = torch.cat((Stance,\n",
        "                                        output_Conclusion_wdrop,\n",
        "                                        output_Premise_wdrop),\n",
        "                                       dim=1)\n",
        "\n",
        "        output = F.relu(self.l3(concatenated_input))\n",
        "        output = F.relu(self.l5(output))\n",
        "        output = self.l6(output)\n",
        "        return output\n",
        "\n",
        "ultima_model = UltimaClass()\n",
        "ultima_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "9OAIwemnvjK7",
        "outputId": "4d061c4f-66ac-492e-d3e4-e03aeaa5bedc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bda462fa1a2c>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0multima_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUltimaClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0multima_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the loss function which is binary cross entropy with logits as our problem is multi-label classification and we don't use sigmoid layers before we get our output (BCEWithLogitsLoss is more stable than normal BCE Loss)"
      ],
      "metadata": {
        "id": "a7pO8xyQwpbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "metadata": {
        "id": "Ho_i0dEpx8mt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loops:"
      ],
      "metadata": {
        "id": "L3K-YpUhzwDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainBert(model, dataloader, optimizer, scheduler, LEARNING_RATE, EPOCHS, epoch, name):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, data in enumerate(dataloader, 0):\n",
        "        ids = data[f'{name}_ids'].to(device, dtype = torch.long)\n",
        "        mask = data[f'{name}_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data[f'{name}_token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        if batch%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "            print()\n",
        "            # print(f\"outputs: {outputs}\")\n",
        "            # print(f\"targets: {targets}\")\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(ids)\n",
        "            print(f\"Train loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "RsxJW1SanaaN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ultima_train(model, dataloader, optimizer, scheduler, LEARNING_RATE, EPOCHS, epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, data in enumerate(dataloader, 0):\n",
        "\n",
        "        Stance = data['Stance']\n",
        "\n",
        "        conclusion_ids = data['C_ids'].to(device, dtype = torch.long)\n",
        "        conclusion_mask = data['C_mask'].to(device, dtype = torch.long)\n",
        "        conclusion_token_type_ids = data['C_token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "        premise_ids = data['Premise_ids'].to(device, dtype = torch.long)\n",
        "        premise_mask = data['Premise_mask'].to(device, dtype = torch.long)\n",
        "        premise_token_type_ids = data['Premise_token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(Stance,\n",
        "                conclusion_ids,\n",
        "                conclusion_mask,\n",
        "                conclusion_token_type_ids,\n",
        "                premise_ids,\n",
        "                premise_mask,\n",
        "                premise_token_type_ids)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        if batch%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "            print()\n",
        "            # print(f\"outputs: {outputs}\")\n",
        "            # print(f\"targets: {targets}\")\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(ids)\n",
        "            print(f\"Train loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "RhIXJdyG6I-_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation loops:"
      ],
      "metadata": {
        "id": "6mkScnxLzzMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(epoch, val_loss_min_input, model, dataloader, name):\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(dataloader, 0):\n",
        "            ids = data[f'{name}_ids'].to(device, dtype = torch.long)\n",
        "            mask = data[f'{name}_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data[f'{name}_token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            val_loss += loss_fn(outputs, targets).item()\n",
        "\n",
        "        val_loss /= num_batches\n",
        "        print(val_loss)\n",
        "        #outputs, targets = fin_outputs, fin_targets\n",
        "        print(f\"\\nValidation loss: {val_loss:>8f}.\")\n",
        "        if val_loss <= val_loss_min_input:\n",
        "            #create checkpoint variable and add important data\n",
        "            if epoch > 0:\n",
        "                print('Validation loss decreased ({:.8f} --> {:.8f}).  Saving model ...'.format(val_loss_min_input, val_loss))\n",
        "            else: print('Saving model ...')\n",
        "            # save best model\n",
        "            torch.save(model.state_dict(), f\"{name}_model.pth\")\n",
        "            print(\"Saved PyTorch Model State to model.pth\\n\")\n",
        "            val_loss_min_input = val_loss\n",
        "        else:\n",
        "          print('validation loss didn\\'t go down -____-')\n",
        "    return val_loss_min_input"
      ],
      "metadata": {
        "id": "Zo0UqknVkleF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ultima_validation(epoch, val_loss_min_input, model, dataloader, name):\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(dataloader, 0):\n",
        "            Stance = data['Stance']\n",
        "\n",
        "            conclusion_ids = data['C_ids'].to(device, dtype = torch.long)\n",
        "            conclusion_mask = data['C_mask'].to(device, dtype = torch.long)\n",
        "            conclusion_token_type_ids = data['C_token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "            premise_ids = data['Premise_ids'].to(device, dtype = torch.long)\n",
        "            premise_mask = data['Premise_mask'].to(device, dtype = torch.long)\n",
        "            premise_token_type_ids = data['Premise_token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(Stance,\n",
        "                conclusion_ids,\n",
        "                conclusion_mask,\n",
        "                conclusion_token_type_ids,\n",
        "                premise_ids,\n",
        "                premise_mask,\n",
        "                premise_token_type_ids)\n",
        "\n",
        "            val_loss += loss_fn(outputs, targets).item()\n",
        "\n",
        "        val_loss /= num_batches\n",
        "        print(val_loss)\n",
        "        #outputs, targets = fin_outputs, fin_targets\n",
        "        print(f\"\\nValidation loss: {val_loss:>8f}.\")\n",
        "        if val_loss <= val_loss_min_input:\n",
        "            #create checkpoint variable and add important data\n",
        "            if epoch > 0:\n",
        "                print('Validation loss decreased ({:.8f} --> {:.8f}).  Saving model ...'.format(val_loss_min_input, val_loss))\n",
        "            else: print('Saving model ...')\n",
        "            # save best model\n",
        "            torch.save(model.state_dict(), f\"{name}_model.pth\")\n",
        "            print(\"Saved PyTorch Model State to model.pth\\n\")\n",
        "            val_loss_min_input = val_loss\n",
        "        else:\n",
        "          print('validation loss didn\\'t go down -____-')\n",
        "    return val_loss_min_input"
      ],
      "metadata": {
        "id": "0hEUdsUz8Ic7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test loop:"
      ],
      "metadata": {
        "id": "1PpS7GMKz1yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader, name):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(data_loader, 0):\n",
        "            ids = data[f'{name}_ids'].to(device, dtype = torch.long)\n",
        "            mask = data[f'{name}_mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data[f'{name}_token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "z0iU4B23mmE4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ultima_test(model, data_loader, name):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(data_loader, 0):\n",
        "            Stance = data['Stance']\n",
        "\n",
        "            conclusion_ids = data['C_ids'].to(device, dtype = torch.long)\n",
        "            conclusion_mask = data['C_mask'].to(device, dtype = torch.long)\n",
        "            conclusion_token_type_ids = data['C_token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "            premise_ids = data['Premise_ids'].to(device, dtype = torch.long)\n",
        "            premise_mask = data['Premise_mask'].to(device, dtype = torch.long)\n",
        "            premise_token_type_ids = data['Premise_token_type_ids'].to(device, dtype = torch.long)\n",
        "\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(Stance,\n",
        "                conclusion_ids,\n",
        "                conclusion_mask,\n",
        "                conclusion_token_type_ids,\n",
        "                premise_ids,\n",
        "                premise_mask,\n",
        "                premise_token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "dfIJClK18lh5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we find the best threshold for our logits"
      ],
      "metadata": {
        "id": "g-db62zsz5SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_threshold(model, dataloader, name):\n",
        "    outputs, targets = test(model, dataloader, name)\n",
        "    results = {}\n",
        "    for tr in np.arange(0.1, 0.9, 0.5):\n",
        "        tr = round(tr, 2)\n",
        "        predictions= np.array(outputs) >= tr\n",
        "        f1 = f1_score(targets, predictions, average='macro', zero_division=1)\n",
        "        results[tr] = f1\n",
        "\n",
        "    return max(results, key=results.get), results, outputs, targets"
      ],
      "metadata": {
        "id": "1ugF_d0Kmo1p"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT w/C"
      ],
      "metadata": {
        "id": "fgad0rw5Yppp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(training_loader)*EPOCHS\n",
        "\n",
        "optimizer = torch.optim.Adam(params=C_model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "p2gG3AdCY5ZW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=\"C\"\n",
        "\n",
        "val_loss_min = np.Inf\n",
        "for epoch in range(EPOCHS):\n",
        "  trainBert(C_model,\n",
        "            training_loader,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            LEARNING_RATE,\n",
        "            EPOCHS,\n",
        "            epoch,\n",
        "            name)\n",
        "  val_loss_min = validation(epoch,\n",
        "                            val_loss_min,\n",
        "                            CPS_model,\n",
        "                            validation_loader,\n",
        "                            name)"
      ],
      "metadata": {
        "id": "_bL1qhP8aAFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae9e23f-cb8f-4ca1-aada-cdb297acac82"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.7006109952926636\n",
            "\n",
            "Train loss: 0.700611  [    0/ 5393]\n",
            "Train loss: 0.641512  [  800/ 5393]\n",
            "Train loss: 0.615408  [ 1600/ 5393]\n",
            "Train loss: 0.731518  [ 2400/ 5393]\n",
            "Train loss: 0.662632  [ 3200/ 5393]\n",
            "Train loss: 0.604468  [ 4000/ 5393]\n",
            "Train loss: 0.575522  [ 4800/ 5393]\n",
            "0.6963742367828949\n",
            "\n",
            "Validation loss: 0.696374.\n",
            "Saving model ...\n",
            "Saved PyTorch Model State to model.pth\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th, results_c, outputs_c, targets_c= get_threshold(C_model, validation_loader, name)\n",
        "print(f\"Best threshold: {th}, F1-score: {results_c[th]}\")\n",
        "predictions_c = np.array(outputs_c) >= th\n",
        "report_c = classification_report(targets_c, predictions_c, target_names=labels ,zero_division=1)\n",
        "print(report_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzUHdH7u1X5C",
        "outputId": "0b39d1ac-9c76-4885-8cd4-96f01b82090c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold: 0.1, F1-score: 0.7343411653971421\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Openness to change       0.37      1.00      0.54       698\n",
            "      Conservation       0.49      1.00      0.66       924\n",
            "  Self-enhancement       0.75      1.00      0.86      1426\n",
            "Self-transcendence       0.79      1.00      0.89      1506\n",
            "\n",
            "         micro avg       0.60      1.00      0.75      4554\n",
            "         macro avg       0.60      1.00      0.73      4554\n",
            "      weighted avg       0.65      1.00      0.78      4554\n",
            "       samples avg       0.60      1.00      0.73      4554\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT w/ CP"
      ],
      "metadata": {
        "id": "0WjEi7-pYukE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(training_loader)*EPOCHS\n",
        "\n",
        "optimizer = torch.optim.Adam(params=CP_model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "ccY9swK_Z5M-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=\"CP\"\n",
        "\n",
        "val_loss_min = np.Inf\n",
        "for epoch in range(EPOCHS):\n",
        "  trainBert(CP_model,\n",
        "            training_loader,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            LEARNING_RATE,\n",
        "            EPOCHS,\n",
        "            epoch,\n",
        "            name)\n",
        "  val_loss_min = validation(epoch,\n",
        "                            val_loss_min,\n",
        "                            CPS_model,\n",
        "                            validation_loader,\n",
        "                            name)"
      ],
      "metadata": {
        "id": "F6CJkE0kaB8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8802d7e5-17c3-42a2-ca36-cedffbdc8aec"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.6870609521865845\n",
            "\n",
            "Train loss: 0.687061  [    0/ 5393]\n",
            "Train loss: 0.628761  [  800/ 5393]\n",
            "Train loss: 0.613179  [ 1600/ 5393]\n",
            "Train loss: 0.739689  [ 2400/ 5393]\n",
            "Train loss: 0.682210  [ 3200/ 5393]\n",
            "Train loss: 0.564839  [ 4000/ 5393]\n",
            "Train loss: 0.535126  [ 4800/ 5393]\n",
            "0.6962551215529945\n",
            "\n",
            "Validation loss: 0.696255.\n",
            "Saving model ...\n",
            "Saved PyTorch Model State to model.pth\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th, results_cp, outputs_cp, targets_cp= get_threshold(CP_model, validation_loader, name)\n",
        "print(f\"Best threshold: {th}, F1-score: {results_cp[th]}\")\n",
        "predictions_cp = np.array(outputs_cp) >= th\n",
        "report_cp = classification_report(targets_cp, predictions_cp, target_names=labels ,zero_division=1)\n",
        "print(report_cp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXb6fJy62wFv",
        "outputId": "e93fbb7f-b8ed-4585-e058-01846adeb8f1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold: 0.1, F1-score: 0.7343411653971421\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Openness to change       0.37      1.00      0.54       698\n",
            "      Conservation       0.49      1.00      0.66       924\n",
            "  Self-enhancement       0.75      1.00      0.86      1426\n",
            "Self-transcendence       0.79      1.00      0.89      1506\n",
            "\n",
            "         micro avg       0.60      1.00      0.75      4554\n",
            "         macro avg       0.60      1.00      0.73      4554\n",
            "      weighted avg       0.65      1.00      0.78      4554\n",
            "       samples avg       0.60      1.00      0.73      4554\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT w/ CPS"
      ],
      "metadata": {
        "id": "wYfC-BR2YxPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(training_loader)*EPOCHS\n",
        "\n",
        "optimizer = torch.optim.Adam(params=CPS_model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "NjVwCshAtTn5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=\"CPS\"\n",
        "\n",
        "val_loss_min = np.Inf\n",
        "for epoch in range(EPOCHS):\n",
        "  trainBert(CPS_model,\n",
        "            training_loader,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            LEARNING_RATE,\n",
        "            EPOCHS,\n",
        "            epoch,\n",
        "            name)\n",
        "  val_loss_min = validation(epoch,\n",
        "                            val_loss_min,\n",
        "                            CPS_model,\n",
        "                            validation_loader,\n",
        "                            name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2NO5q7YrFjp",
        "outputId": "71e828ee-49c4-4c05-df78-1145b454ec19"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.70072340965271\n",
            "\n",
            "Train loss: 0.700723  [    0/ 5393]\n",
            "Train loss: 0.629930  [  800/ 5393]\n",
            "Train loss: 0.610783  [ 1600/ 5393]\n",
            "Train loss: 0.725022  [ 2400/ 5393]\n",
            "Train loss: 0.758958  [ 3200/ 5393]\n",
            "Train loss: 0.562462  [ 4000/ 5393]\n",
            "Train loss: 0.525280  [ 4800/ 5393]\n",
            "0.5507644657595752\n",
            "\n",
            "Validation loss: 0.550764.\n",
            "Saving model ...\n",
            "Saved PyTorch Model State to model.pth\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th, results_cps, outputs_cps, targets_cps= get_threshold(CPS_model, validation_loader, name)\n",
        "print(f\"Best threshold: {th}, F1-score: {results_cps[th]}\")\n",
        "predictions_cps = np.array(outputs_cps) >= th\n",
        "report_cps = classification_report(targets_cps, predictions_cps, target_names=labels ,zero_division=1)\n",
        "print(report_cps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGRggj0b3CQU",
        "outputId": "12226251-233b-42cf-9566-a2a2076b86b9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold: 0.1, F1-score: 0.7343411653971421\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Openness to change       0.37      1.00      0.54       698\n",
            "      Conservation       0.49      1.00      0.66       924\n",
            "  Self-enhancement       0.75      1.00      0.86      1426\n",
            "Self-transcendence       0.79      1.00      0.89      1506\n",
            "\n",
            "         micro avg       0.60      1.00      0.75      4554\n",
            "         macro avg       0.60      1.00      0.73      4554\n",
            "      weighted avg       0.65      1.00      0.78      4554\n",
            "       samples avg       0.60      1.00      0.73      4554\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultimate model:"
      ],
      "metadata": {
        "id": "XLkibSGJ5mGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(training_loader)*EPOCHS\n",
        "\n",
        "optimizer = torch.optim.Adam(params=CPS_model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "FS8MyyHlx9Ip"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=\"ultima\"\n",
        "\n",
        "val_loss_min = np.Inf\n",
        "for epoch in range(EPOCHS):\n",
        "  ultima_train(ultima_model,\n",
        "            training_loader,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            LEARNING_RATE,\n",
        "            EPOCHS,\n",
        "            epoch)\n",
        "  val_loss_min = ultima_validation(epoch,\n",
        "                            val_loss_min,\n",
        "                            ultima_model,\n",
        "                            validation_loader,\n",
        "                            name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0LwTCpB_yFiW",
        "outputId": "435668e1-dcd7-4d9e-c30e-931635854cb3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5f6069d388c4>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   ultima_train(ultima_model,\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-6d8440a3010f>\u001b[0m in \u001b[0;36multima_train\u001b[0;34m(model, dataloader, optimizer, scheduler, LEARNING_RATE, EPOCHS, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mStance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mconclusion_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mconclusion_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mconclusion_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C_token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th, results_ultima, outputs_ultima, targets_ultima= get_threshold(ultima_model, validation_loader)\n",
        "print(f\"Best threshold: {th}, F1-score: {results_ultima[th]}\")\n",
        "predictions_ultima = np.array(outputs_ultima) >= th\n",
        "report_roberta_ultima = classification_report(targets_ultima, predictions_ultima, target_names=labels ,zero_division=1)\n",
        "print(report_roberta_ultima)"
      ],
      "metadata": {
        "id": "vKrMXtHP3OqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One important fact is that since the main goal is getting a good F1 score not a high accuracy; we believe we could've used a custom loss function to further improve the results."
      ],
      "metadata": {
        "id": "VmjEazvd4EYv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzoIQTDW4v8R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}